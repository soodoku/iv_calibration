{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8222a8-b269-4f01-aee3-71b092736c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot  # Python Optimal Transport library\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def fit_wasserstein_prior(posterior_draws, prior_family='mvn'):\n",
    "    \"\"\"\n",
    "    Fit a parametric prior by minimizing Wasserstein distance\n",
    "    to empirical posterior draws\n",
    "    \"\"\"\n",
    "    D = posterior_draws.shape[1]\n",
    "    \n",
    "    if prior_family == 'mvn':\n",
    "        # Optimize over multivariate normal parameters\n",
    "        def objective(params):\n",
    "            mu = params[:D]\n",
    "            # Ensure positive definite covariance (Cholesky parameterization)\n",
    "            L_vec = params[D:]\n",
    "            L = np.zeros((D, D))\n",
    "            L[np.triu_indices(D)] = L_vec\n",
    "            Sigma = L @ L.T + 1e-6 * np.eye(D)  # Add small regularization\n",
    "            \n",
    "            # Sample from fitted distribution\n",
    "            fitted_samples = multivariate_normal.rvs(mu, Sigma, size=len(posterior_draws))\n",
    "            \n",
    "            # Compute Wasserstein-2 distance\n",
    "            cost_matrix = ot.dist(posterior_draws, fitted_samples, metric='euclidean')\n",
    "            W2_distance = ot.emd2([], [], cost_matrix)\n",
    "            return W2_distance\n",
    "        \n",
    "        # Initialize with sample mean and covariance\n",
    "        init_mu = np.mean(posterior_draws, axis=0)\n",
    "        init_cov = np.cov(posterior_draws.T)\n",
    "        L_init = np.linalg.cholesky(init_cov)\n",
    "        init_params = np.concatenate([init_mu, L_init[np.triu_indices(D)]])\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(objective, init_params, method='L-BFGS-B')\n",
    "        \n",
    "        # Extract optimized parameters\n",
    "        mu_opt = result.x[:D]\n",
    "        L_vec_opt = result.x[D:]\n",
    "        L_opt = np.zeros((D, D))\n",
    "        L_opt[np.triu_indices(D)] = L_vec_opt\n",
    "        Sigma_opt = L_opt @ L_opt.T\n",
    "        \n",
    "        return mu_opt, Sigma_opt\n",
    "\n",
    "# After fitting OH model:\n",
    "beta_OH_draws = fit_OH.stan_variable('beta')\n",
    "\n",
    "# Fit Wasserstein-optimal prior\n",
    "mu_prior, Sigma_prior = fit_wasserstein_prior(beta_OH_draws)\n",
    "\n",
    "# Use in Stan model (modified version)\n",
    "data_NY_wass = {\n",
    "    'N': N, 'D': D, 'x': x_NY, 'y': y_NY,\n",
    "    'mu_prior': mu_prior, 'Sigma_prior': Sigma_prior\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c491884-3080-4d12-8dc8-eac37918a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def simulate_once(n=1000, random_state=None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # Simulate covariate X, instrument Z, and treatment D\n",
    "    X = rng.uniform(-1, 1, size=(n, 1))\n",
    "    Z = rng.binomial(1, 0.5, size=(n, 1))\n",
    "    logits = 1.0 * Z.ravel() + 0.5 * X.ravel()\n",
    "    p_true = 1 / (1 + np.exp(-logits))\n",
    "    D = rng.binomial(1, p_true)\n",
    "    \n",
    "    # Outcome Y with true beta = 2\n",
    "    beta_true = 2.0\n",
    "    Y = beta_true * D + rng.normal(0, 1, size=n)\n",
    "    \n",
    "    # First-stage ML: Random Forest classifier for D ~ (Z, X)\n",
    "    features = np.hstack([Z, X])\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=rng)\n",
    "    clf.fit(features, D)\n",
    "    p_hat = clf.predict_proba(features)[:, 1]\n",
    "    \n",
    "    # Isotonic calibration\n",
    "    iso = IsotonicRegression(out_of_bounds='clip')\n",
    "    iso.fit(p_hat, D)\n",
    "    p_cal = iso.predict(p_hat)\n",
    "    \n",
    "    # Second-stage estimation: regress Y on fitted values\n",
    "    lr_raw = LinearRegression().fit(p_hat.reshape(-1, 1), Y)\n",
    "    lr_cal = LinearRegression().fit(p_cal.reshape(-1, 1), Y)\n",
    "    \n",
    "    return lr_raw.coef_[0], lr_cal.coef_[0]\n",
    "\n",
    "# Run simulations\n",
    "n_sim = 100\n",
    "results = np.array([simulate_once(random_state=i) for i in range(n_sim)])\n",
    "errors = (results - 2.0) ** 2\n",
    "\n",
    "# Compute MSE for raw vs calibrated first stage\n",
    "mse_raw = errors[:, 0].mean()\n",
    "mse_cal = errors[:, 1].mean()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Method': ['Raw ML First Stage', 'Isotonic-Calibrated'],\n",
    "    'MSE of β̂': [mse_raw, mse_cal]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1748dac8-dd7d-4ba9-8efc-626af30d1b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>MSE of β̂</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw ML First Stage</td>\n",
       "      <td>0.363006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isotonic-Calibrated</td>\n",
       "      <td>0.004333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  MSE of β̂\n",
       "0   Raw ML First Stage   0.363006\n",
       "1  Isotonic-Calibrated   0.004333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302406da-1118-465a-8179-8689952db0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>MSE of β̂</th>\n",
       "      <th>Avg. SE of β̂</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw ML First Stage</td>\n",
       "      <td>0.363006</td>\n",
       "      <td>0.097222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isotonic-Calibrated</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.065673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  MSE of β̂  Avg. SE of β̂\n",
       "0   Raw ML First Stage   0.363006       0.097222\n",
       "1  Isotonic-Calibrated   0.004333       0.065673"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def simulate_iv(n=1000, random_state=None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # Simulate covariate X, instrument Z, and treatment D\n",
    "    X = rng.uniform(-1, 1, size=(n, 1))\n",
    "    Z = rng.binomial(1, 0.5, size=(n, 1))\n",
    "    logits = 1.0 * Z.ravel() + 0.5 * X.ravel()\n",
    "    p_true = 1 / (1 + np.exp(-logits))\n",
    "    D = rng.binomial(1, p_true)\n",
    "    \n",
    "    # Outcome Y with true beta = 2\n",
    "    beta_true = 2.0\n",
    "    Y = beta_true * D + rng.normal(0, 1, size=n)\n",
    "    \n",
    "    # First-stage ML: Random Forest classifier for D ~ (Z, X)\n",
    "    features = np.hstack([Z, X])\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=rng)\n",
    "    clf.fit(features, D)\n",
    "    p_hat = clf.predict_proba(features)[:, 1]\n",
    "    \n",
    "    # Isotonic calibration\n",
    "    iso = IsotonicRegression(out_of_bounds='clip')\n",
    "    iso.fit(p_hat, D)\n",
    "    p_cal = iso.predict(p_hat)\n",
    "    \n",
    "    # Second-stage OLS using predicted probabilities as regressors\n",
    "    def second_stage(regressor):\n",
    "        X2 = sm.add_constant(regressor)\n",
    "        model = sm.OLS(Y, X2).fit()\n",
    "        coef = model.params[1]\n",
    "        se = model.bse[1]\n",
    "        return coef, se\n",
    "    \n",
    "    coef_raw, se_raw = second_stage(p_hat)\n",
    "    coef_cal, se_cal = second_stage(p_cal)\n",
    "    \n",
    "    return coef_raw, se_raw, coef_cal, se_cal\n",
    "\n",
    "# Run simulations\n",
    "n_sim = 100\n",
    "results = np.array([simulate_iv(random_state=i) for i in range(n_sim)])\n",
    "coefs = results[:, [0, 2]]\n",
    "ses = results[:, [1, 3]]\n",
    "errors = (coefs - 2.0) ** 2\n",
    "\n",
    "mse_raw = errors[:, 0].mean()\n",
    "mse_cal = errors[:, 1].mean()\n",
    "se_mean_raw = ses[:, 0].mean()\n",
    "se_mean_cal = ses[:, 1].mean()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Method': ['Raw ML First Stage', 'Isotonic-Calibrated'],\n",
    "    'MSE of β̂': [mse_raw, mse_cal],\n",
    "    'Avg. SE of β̂': [se_mean_raw, se_mean_cal]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56ea2fc-f677-4eeb-8a50-2e349a7bdef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation study...\n",
      "Running scenario: Strong instrument\n",
      "Running scenario: Weak instrument\n",
      "Running scenario: Very strong instrument\n",
      "\n",
      "Analyzing results...\n",
      "=== Simulation Results Summary ===\n",
      "                                      Beta Mean  Beta Std    Bias        MSE  \\\n",
      "scenario               method                                                  \n",
      "Strong instrument      Linear 2SLS       2.0406    0.5746  0.0406     0.3302   \n",
      "                       Logistic          2.0792    0.5827  0.0792     0.3441   \n",
      "                       RF Calibrated     2.3561    0.2487  0.3561     0.1884   \n",
      "                       RF Raw            4.1458    0.5849  2.1458     4.9449   \n",
      "Very strong instrument Linear 2SLS       2.0229    0.2823  0.0229     0.0798   \n",
      "                       Logistic          2.0616    0.2854  0.0616     0.0848   \n",
      "                       RF Calibrated     2.1499    0.1745  0.1499     0.0528   \n",
      "                       RF Raw            3.1185    0.3294  1.1185     1.3589   \n",
      "Weak instrument        Linear 2SLS       0.6178   33.5318 -1.3822  1120.6716   \n",
      "                       Logistic          2.4581   10.6044  0.4581   112.0999   \n",
      "                       RF Calibrated     2.5279    0.3227  0.5279     0.3823   \n",
      "                       RF Raw            4.9538    0.7071  2.9538     9.2226   \n",
      "\n",
      "                                       F-stat  Partial R²      R²  Cal Error  \n",
      "scenario               method                                                 \n",
      "Strong instrument      Linear 2SLS    16.6694      0.0164  0.0368     0.0000  \n",
      "                       Logistic       16.6694      0.0164  0.0368     0.0000  \n",
      "                       RF Calibrated  16.6694      0.0164  0.2187     0.0000  \n",
      "                       RF Raw         16.6694      0.0164  0.1476     0.0925  \n",
      "Very strong instrument Linear 2SLS    61.5268      0.0579  0.0752     0.0000  \n",
      "                       Logistic       61.5268      0.0579  0.0755     0.0000  \n",
      "                       RF Calibrated  61.5268      0.0579  0.2490     0.0000  \n",
      "                       RF Raw         61.5268      0.0579  0.1852     0.0836  \n",
      "Weak instrument        Linear 2SLS     3.6973      0.0037  0.0243     0.0000  \n",
      "                       Logistic        3.6973      0.0037  0.0244     0.0000  \n",
      "                       RF Calibrated   3.6973      0.0037  0.2137     0.0000  \n",
      "                       RF Raw          3.6973      0.0037  0.1360     0.1004  \n",
      "\n",
      "=== Main Results (Strong Instrument) ===\n",
      "               f_stat  partial_r2    mse\n",
      "method                                  \n",
      "Linear 2SLS    16.669       0.016  0.330\n",
      "Logistic       16.669       0.016  0.344\n",
      "RF Calibrated  16.669       0.016  0.188\n",
      "RF Raw         16.669       0.016  4.945\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def simulate_2sls_data(n=1000, z_coef=0.5, x_coef=0.5, beta_true=2.0, random_state=None):\n",
    "    \"\"\"Simulate data for 2SLS with binary treatment\"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    # Covariates and instruments\n",
    "    X = rng.uniform(-1, 1, size=n)\n",
    "    Z = rng.binomial(1, 0.5, size=n)\n",
    "    \n",
    "    # Treatment equation: D = f(Z, X, u)\n",
    "    logits = z_coef * Z + x_coef * X\n",
    "    prob_D = 1 / (1 + np.exp(-logits))\n",
    "    D = rng.binomial(1, prob_D)\n",
    "    \n",
    "    # Outcome equation: Y = beta*D + X + error\n",
    "    # Include X in outcome to create endogeneity if it affects both D and Y\n",
    "    error = rng.normal(0, 1, size=n)\n",
    "    Y = beta_true * D + 1.0 * X + error\n",
    "    \n",
    "    return {'X': X, 'Z': Z, 'D': D, 'Y': Y, 'prob_D_true': prob_D}\n",
    "\n",
    "def run_proper_2sls(Y, D, Z, X, d_hat):\n",
    "    \"\"\"Run proper 2SLS using fitted values from first stage\"\"\"\n",
    "    n = len(Y)\n",
    "    \n",
    "    # Second stage: regress Y on D_hat and X\n",
    "    X_matrix = np.column_stack([np.ones(n), d_hat, X])\n",
    "    \n",
    "    # Compute 2SLS estimator\n",
    "    try:\n",
    "        beta_hat = np.linalg.solve(X_matrix.T @ X_matrix, X_matrix.T @ Y)\n",
    "        \n",
    "        # Compute standard errors (simplified - doesn't account for first-stage uncertainty)\n",
    "        residuals = Y - X_matrix @ beta_hat\n",
    "        sigma2 = np.sum(residuals**2) / (n - X_matrix.shape[1])\n",
    "        var_beta = sigma2 * np.linalg.inv(X_matrix.T @ X_matrix)\n",
    "        se_beta = np.sqrt(np.diag(var_beta))\n",
    "        \n",
    "        return beta_hat[1], se_beta[1]  # Return coefficient on D_hat\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def compute_first_stage_stats(D, Z, X, d_hat):\n",
    "    \"\"\"Compute first-stage F-statistic and partial R-squared\"\"\"\n",
    "    n = len(D)\n",
    "    \n",
    "    # Regression of D on Z, X\n",
    "    X_full = np.column_stack([np.ones(n), Z, X])\n",
    "    \n",
    "    try:\n",
    "        # OLS coefficients\n",
    "        coefs = np.linalg.solve(X_full.T @ X_full, X_full.T @ D)\n",
    "        \n",
    "        # Fitted values and residuals\n",
    "        D_fitted = X_full @ coefs\n",
    "        residuals_full = D - D_fitted\n",
    "        \n",
    "        # Regression of D on just X (restricted model)\n",
    "        X_restricted = np.column_stack([np.ones(n), X])\n",
    "        coefs_restricted = np.linalg.solve(X_restricted.T @ X_restricted, X_restricted.T @ D)\n",
    "        D_fitted_restricted = X_restricted @ coefs_restricted\n",
    "        residuals_restricted = D - D_fitted_restricted\n",
    "        \n",
    "        # F-statistic for testing Z's significance\n",
    "        rss_full = np.sum(residuals_full**2)\n",
    "        rss_restricted = np.sum(residuals_restricted**2)\n",
    "        f_stat = ((rss_restricted - rss_full) / 1) / (rss_full / (n - 3))\n",
    "        \n",
    "        # Partial R-squared of Z\n",
    "        partial_r2 = (rss_restricted - rss_full) / rss_restricted\n",
    "        \n",
    "        # R-squared using d_hat predictions\n",
    "        r2_dhat = 1 - np.sum((D - d_hat)**2) / np.sum((D - np.mean(D))**2)\n",
    "        \n",
    "        return f_stat, partial_r2, r2_dhat\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "def calibration_diagnostics(y_true, y_prob):\n",
    "    \"\"\"Compute calibration diagnostics\"\"\"\n",
    "    # Bin predictions and compute empirical frequencies\n",
    "    n_bins = 10\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    digitized = np.digitize(y_prob, bins) - 1\n",
    "    digitized = np.clip(digitized, 0, n_bins - 1)\n",
    "    \n",
    "    empirical_prob = np.zeros(n_bins)\n",
    "    pred_prob = np.zeros(n_bins)\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = digitized == i\n",
    "        if np.sum(mask) > 0:\n",
    "            empirical_prob[i] = np.mean(y_true[mask])\n",
    "            pred_prob[i] = np.mean(y_prob[mask])\n",
    "    \n",
    "    # Brier score and calibration error\n",
    "    brier_score = np.mean((y_prob - y_true)**2)\n",
    "    calibration_error = np.mean(np.abs(pred_prob - empirical_prob))\n",
    "    \n",
    "    return {\n",
    "        'brier_score': brier_score,\n",
    "        'calibration_error': calibration_error,\n",
    "        'bin_centers': bin_centers,\n",
    "        'empirical_prob': empirical_prob,\n",
    "        'pred_prob': pred_prob\n",
    "    }\n",
    "\n",
    "def simulation_study():\n",
    "    \"\"\"Run comprehensive simulation study\"\"\"\n",
    "    n_sim = 200\n",
    "    n_obs = 1000\n",
    "    scenarios = [\n",
    "        {'z_coef': 0.5, 'name': 'Strong instrument'},\n",
    "        {'z_coef': 0.2, 'name': 'Weak instrument'},\n",
    "        {'z_coef': 1.0, 'name': 'Very strong instrument'}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(f\"Running scenario: {scenario['name']}\")\n",
    "        \n",
    "        for sim in range(n_sim):\n",
    "            # Generate data\n",
    "            data = simulate_2sls_data(\n",
    "                n=n_obs, \n",
    "                z_coef=scenario['z_coef'],\n",
    "                random_state=sim\n",
    "            )\n",
    "            \n",
    "            X, Z, D, Y = data['X'], data['Z'], data['D'], data['Y']\n",
    "            \n",
    "            # Stack features for ML\n",
    "            features = np.column_stack([Z, X])\n",
    "            \n",
    "            # Method 1: Linear 2SLS (baseline)\n",
    "            X_fs = np.column_stack([np.ones(len(D)), Z, X])\n",
    "            coefs_linear = np.linalg.solve(X_fs.T @ X_fs, X_fs.T @ D)\n",
    "            d_hat_linear = X_fs @ coefs_linear\n",
    "            beta_linear, se_linear = run_proper_2sls(Y, D, Z, X, d_hat_linear)\n",
    "            f_stat_linear, partial_r2_linear, r2_linear = compute_first_stage_stats(D, Z, X, d_hat_linear)\n",
    "            \n",
    "            # Method 2: Random Forest (raw)\n",
    "            rf = RandomForestClassifier(n_estimators=100, random_state=sim, max_depth=5)\n",
    "            rf.fit(features, D)\n",
    "            p_hat_rf = rf.predict_proba(features)[:, 1]\n",
    "            beta_rf_raw, se_rf_raw = run_proper_2sls(Y, D, Z, X, p_hat_rf)\n",
    "            f_stat_rf_raw, partial_r2_rf_raw, r2_rf_raw = compute_first_stage_stats(D, Z, X, p_hat_rf)\n",
    "            \n",
    "            # Calibration diagnostics for raw RF\n",
    "            cal_diag_raw = calibration_diagnostics(D, p_hat_rf)\n",
    "            \n",
    "            # Method 3: Random Forest + Isotonic calibration\n",
    "            iso = IsotonicRegression(out_of_bounds='clip')\n",
    "            iso.fit(p_hat_rf, D)\n",
    "            p_hat_rf_cal = iso.predict(p_hat_rf)\n",
    "            beta_rf_cal, se_rf_cal = run_proper_2sls(Y, D, Z, X, p_hat_rf_cal)\n",
    "            f_stat_rf_cal, partial_r2_rf_cal, r2_rf_cal = compute_first_stage_stats(D, Z, X, p_hat_rf_cal)\n",
    "            \n",
    "            # Calibration diagnostics for calibrated RF\n",
    "            cal_diag_cal = calibration_diagnostics(D, p_hat_rf_cal)\n",
    "            \n",
    "            # Method 4: Logistic regression (should be well-calibrated)\n",
    "            lr = LogisticRegression(random_state=sim)\n",
    "            lr.fit(features, D)\n",
    "            p_hat_lr = lr.predict_proba(features)[:, 1]\n",
    "            beta_lr, se_lr = run_proper_2sls(Y, D, Z, X, p_hat_lr)\n",
    "            f_stat_lr, partial_r2_lr, r2_lr = compute_first_stage_stats(D, Z, X, p_hat_lr)\n",
    "            \n",
    "            # Store results\n",
    "            for method, beta, se, f_stat, partial_r2, r2, cal_error in [\n",
    "                ('Linear 2SLS', beta_linear, se_linear, f_stat_linear, partial_r2_linear, r2_linear, 0),\n",
    "                ('RF Raw', beta_rf_raw, se_rf_raw, f_stat_rf_raw, partial_r2_rf_raw, r2_rf_raw, cal_diag_raw['calibration_error']),\n",
    "                ('RF Calibrated', beta_rf_cal, se_rf_cal, f_stat_rf_cal, partial_r2_rf_cal, r2_rf_cal, cal_diag_cal['calibration_error']),\n",
    "                ('Logistic', beta_lr, se_lr, f_stat_lr, partial_r2_lr, r2_lr, 0)\n",
    "            ]:\n",
    "                results.append({\n",
    "                    'scenario': scenario['name'],\n",
    "                    'z_coef': scenario['z_coef'],\n",
    "                    'sim': sim,\n",
    "                    'method': method,\n",
    "                    'beta_hat': beta,\n",
    "                    'se': se,\n",
    "                    'f_stat': f_stat,\n",
    "                    'partial_r2': partial_r2,\n",
    "                    'r2': r2,\n",
    "                    'calibration_error': cal_error,\n",
    "                    'bias': beta - 2.0 if not np.isnan(beta) else np.nan,\n",
    "                    'mse': (beta - 2.0)**2 if not np.isnan(beta) else np.nan\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def analyze_results(results_df):\n",
    "    \"\"\"Analyze and display simulation results\"\"\"\n",
    "    \n",
    "    # Summary statistics by method and scenario\n",
    "    summary = results_df.groupby(['scenario', 'method']).agg({\n",
    "        'beta_hat': ['mean', 'std'],\n",
    "        'bias': 'mean',\n",
    "        'mse': 'mean',\n",
    "        'f_stat': 'mean',\n",
    "        'partial_r2': 'mean',\n",
    "        'r2': 'mean',\n",
    "        'calibration_error': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    summary.columns = ['Beta Mean', 'Beta Std', 'Bias', 'MSE', 'F-stat', 'Partial R²', 'R²', 'Cal Error']\n",
    "    \n",
    "    print(\"=== Simulation Results Summary ===\")\n",
    "    print(summary)\n",
    "    \n",
    "    # Focus on strong instrument scenario for main results\n",
    "    strong_results = results_df[results_df['scenario'] == 'Strong instrument']\n",
    "    \n",
    "    main_summary = strong_results.groupby('method').agg({\n",
    "        'f_stat': 'mean',\n",
    "        'partial_r2': 'mean', \n",
    "        'mse': 'mean',\n",
    "        'se': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"\\n=== Main Results (Strong Instrument) ===\")\n",
    "    print(main_summary[['f_stat', 'partial_r2', 'mse']])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Run the simulation\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting simulation study...\")\n",
    "    results = simulation_study()\n",
    "    \n",
    "    print(\"\\nAnalyzing results...\")\n",
    "    summary = analyze_results(results)\n",
    "    \n",
    "    # Save results\n",
    "    results.to_csv('2sls_calibration_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294e700e-b846-44d2-b65b-0326771cf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">beta_hat</th>\n",
       "      <th>bias</th>\n",
       "      <th>mse</th>\n",
       "      <th>se_beta</th>\n",
       "      <th>f_stat</th>\n",
       "      <th>partial_r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Strong instrument</th>\n",
       "      <th>Linear 2SLS</th>\n",
       "      <td>2.041</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.771</td>\n",
       "      <td>16.669</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Calibrated</th>\n",
       "      <td>2.360</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.214</td>\n",
       "      <td>16.669</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Raw</th>\n",
       "      <td>4.148</td>\n",
       "      <td>0.583</td>\n",
       "      <td>2.148</td>\n",
       "      <td>4.951</td>\n",
       "      <td>0.425</td>\n",
       "      <td>16.669</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Very strong instrument</th>\n",
       "      <th>Linear 2SLS</th>\n",
       "      <td>2.023</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.383</td>\n",
       "      <td>61.527</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Calibrated</th>\n",
       "      <td>2.149</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.187</td>\n",
       "      <td>61.527</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Raw</th>\n",
       "      <td>3.122</td>\n",
       "      <td>0.326</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.366</td>\n",
       "      <td>0.307</td>\n",
       "      <td>61.527</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Weak instrument</th>\n",
       "      <th>Linear 2SLS</th>\n",
       "      <td>0.618</td>\n",
       "      <td>33.532</td>\n",
       "      <td>-1.382</td>\n",
       "      <td>1120.672</td>\n",
       "      <td>8.370</td>\n",
       "      <td>3.697</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Calibrated</th>\n",
       "      <td>2.543</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.226</td>\n",
       "      <td>3.697</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Raw</th>\n",
       "      <td>4.961</td>\n",
       "      <td>0.699</td>\n",
       "      <td>2.961</td>\n",
       "      <td>9.255</td>\n",
       "      <td>0.495</td>\n",
       "      <td>3.697</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     beta_hat           bias       mse  \\\n",
       "                                         mean     std   mean      mean   \n",
       "scenario               method                                            \n",
       "Strong instrument      Linear 2SLS      2.041   0.575  0.041     0.330   \n",
       "                       RF Calibrated    2.360   0.249  0.360     0.191   \n",
       "                       RF Raw           4.148   0.583  2.148     4.951   \n",
       "Very strong instrument Linear 2SLS      2.023   0.282  0.023     0.080   \n",
       "                       RF Calibrated    2.149   0.174  0.149     0.052   \n",
       "                       RF Raw           3.122   0.326  1.122     1.366   \n",
       "Weak instrument        Linear 2SLS      0.618  33.532 -1.382  1120.672   \n",
       "                       RF Calibrated    2.543   0.316  0.543     0.394   \n",
       "                       RF Raw           4.961   0.699  2.961     9.255   \n",
       "\n",
       "                                     se_beta  f_stat partial_r2  \n",
       "                                        mean    mean       mean  \n",
       "scenario               method                                    \n",
       "Strong instrument      Linear 2SLS     0.771  16.669      0.016  \n",
       "                       RF Calibrated   0.214  16.669      0.016  \n",
       "                       RF Raw          0.425  16.669      0.016  \n",
       "Very strong instrument Linear 2SLS     0.383  61.527      0.058  \n",
       "                       RF Calibrated   0.187  61.527      0.058  \n",
       "                       RF Raw          0.307  61.527      0.058  \n",
       "Weak instrument        Linear 2SLS     8.370   3.697      0.004  \n",
       "                       RF Calibrated   0.226   3.697      0.004  \n",
       "                       RF Raw          0.495   3.697      0.004  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def simulate_2sls_data(n=1000, z_coef=0.5, x_coef=0.5, beta_true=2.0, random_state=None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = rng.uniform(-1, 1, size=n)\n",
    "    Z = rng.binomial(1, 0.5, size=n)\n",
    "    logits = z_coef * Z + x_coef * X\n",
    "    p_D = 1 / (1 + np.exp(-logits))\n",
    "    D = rng.binomial(1, p_D)\n",
    "    Y = beta_true * D + 1.0 * X + rng.normal(0, 1, size=n)\n",
    "    return X, Z, D, Y\n",
    "\n",
    "def first_stage_ml(Z, X, D, calibrate=False):\n",
    "    features = np.column_stack([Z, X])\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "    rf.fit(features, D)\n",
    "    p_hat = rf.predict_proba(features)[:,1]\n",
    "    if calibrate:\n",
    "        iso = IsotonicRegression(out_of_bounds='clip')\n",
    "        iso.fit(p_hat, D)\n",
    "        p_hat = iso.predict(p_hat)\n",
    "    return p_hat\n",
    "\n",
    "def run_2sls(Y, D_hat, X):\n",
    "    # Equivalent to 2SLS with instrument Z: second stage regresses on fitted values\n",
    "    n = len(Y)\n",
    "    design = np.column_stack([np.ones(n), D_hat, X])\n",
    "    coef = np.linalg.lstsq(design, Y, rcond=None)[0]\n",
    "    resid = Y - design.dot(coef)\n",
    "    sigma2 = (resid**2).sum() / (n - design.shape[1])\n",
    "    cov = sigma2 * np.linalg.inv(design.T.dot(design))\n",
    "    return coef[1], np.sqrt(cov[1,1])\n",
    "\n",
    "def first_stage_stats(D, Z, X, D_hat):\n",
    "    n = len(D)\n",
    "    # Full model\n",
    "    X_full = sm.add_constant(np.column_stack([Z, X]))\n",
    "    res_full = sm.OLS(D, X_full).fit()\n",
    "    # Restricted (no Z)\n",
    "    X_res = sm.add_constant(X)\n",
    "    res_res = sm.OLS(D, X_res).fit()\n",
    "    f_stat = ((res_res.ssr - res_full.ssr) / 1) / (res_full.ssr / (n - X_full.shape[1]))\n",
    "    part_r2 = (res_res.ssr - res_full.ssr) / res_res.ssr\n",
    "    # R2 of D_hat\n",
    "    r2_hat = 1 - np.sum((D - D_hat)**2) / np.sum((D - D.mean())**2)\n",
    "    return f_stat, part_r2, r2_hat\n",
    "\n",
    "def simulation_study(n_sim=200, n=1000):\n",
    "    scenarios = [\n",
    "        (0.5, 'Strong instrument'),\n",
    "        (0.2, 'Weak instrument'),\n",
    "        (1.0, 'Very strong instrument')\n",
    "    ]\n",
    "    records = []\n",
    "    for z_coef, name in scenarios:\n",
    "        for sim in range(n_sim):\n",
    "            X, Z, D, Y = simulate_2sls_data(n=n, z_coef=z_coef, random_state=sim)\n",
    "            # Raw ML\n",
    "            D_hat_raw = first_stage_ml(Z, X, D, calibrate=False)\n",
    "            # Calibrated ML\n",
    "            D_hat_cal = first_stage_ml(Z, X, D, calibrate=True)\n",
    "            # Linear 2SLS baseline\n",
    "            D_hat_lin, _ = run_2sls(D, sm.add_constant(np.column_stack([Z, X])).dot(np.linalg.lstsq(sm.add_constant(np.column_stack([Z, X])), D, rcond=None)[0]), X)\n",
    "            # Actually, baseline uses OLS fitted values\n",
    "            lin_fs = sm.OLS(D, sm.add_constant(np.column_stack([Z, X]))).fit()\n",
    "            D_hat_lin = lin_fs.fittedvalues\n",
    "            \n",
    "            for method, D_hat in [\n",
    "                ('Linear 2SLS', D_hat_lin),\n",
    "                ('RF Raw', D_hat_raw),\n",
    "                ('RF Calibrated', D_hat_cal)\n",
    "            ]:\n",
    "                beta, se = run_2sls(Y, D_hat, X)\n",
    "                f_stat, p_r2, r2 = first_stage_stats(D, Z, X, D_hat)\n",
    "                records.append({\n",
    "                    'scenario': name,\n",
    "                    'method': method,\n",
    "                    'beta_hat': beta,\n",
    "                    'se_beta': se,\n",
    "                    'f_stat': f_stat,\n",
    "                    'partial_r2': p_r2,\n",
    "                    'r2_hat': r2,\n",
    "                    'bias': beta - 2.0,\n",
    "                    'mse': (beta - 2.0)**2\n",
    "                })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Run and summarize\n",
    "df = simulation_study()\n",
    "summary = df.groupby(['scenario','method']).agg({\n",
    "    'beta_hat':['mean','std'],\n",
    "    'bias':'mean',\n",
    "    'mse':'mean',\n",
    "    'se_beta':'mean',\n",
    "    'f_stat':'mean',\n",
    "    'partial_r2':'mean'\n",
    "}).round(3)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1782267-9410-4718-b54b-85b3c49a36f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
